{"3.1": {"title": "ACCESS  CONTROL", "sections": {"3.1.1": {"brief_description": "Limit system access to authorized users, processes acting o n behalf of authorized users, and devices (including  other systems).", "detailed_description": "Access control policies (e.g., identity-  or role- based policies, control matrices, and cryptography)\ncontrol access between active entities or subjects (i.e., users or processes acting on behalf of users)\nand passive entities or objects (e.g., devices, fil es, records, and domains) in systems. Access\nenforcement mechanisms can be employed at the application and service level to provide\nincreased information security. Other systems include systems internal and external to the\norganization. This requirement fo cuses  on account management for systems and applications. The\ndefinition of and enforcement of access authorizations, other th an those determined by account\ntype (e.g., privileged verses non -privileged) are addressed in requirement 3.1.2."}, "3.1.2": {"brief_description": "Limit system access to the types of transactions and functions that authorized users are permitted to execute . THE MEANING OF ORGANIZATIONAL SYS TEMS The term organizational system  is used in many of the recommended CUI security requirements in this publication. This term has a specific meaning regarding the scope of applicability for the security requirements. The requirements apply only to the components of nonfederal systems that process, store, or transmit CUI, or that prov ide protection for  the system components.  The appro priate scoping for the CUI security requirements is an important factor in determining prot ection -related investment decisions and managing security risk for nonfederal organizations that have the responsibility of safeguarding CUI.", "detailed_description": "Organizations  may choose to define access privileges or other attributes by account, by type of\naccount, or a combination of both. System acco unt types include individual, shared , group, system,\nanonymous, guest, emergency, developer, manufacturer, vendor, and temporar y. Other attributes\nrequired for authorizing access include  restrictions on time -of-day, day- of-week, and point -of-\norigin. In defining other account attributes, organizations consider system -related requirements\n(e.g., system upgrades scheduled maintenance ,) and mission or business requirements, (e.g., time\nzone differences, customer requirements, remote access to support travel requirements).\nDerived Security Requirements"}, "3.1.3": {"brief_description": "Control the flow of CUI in accordance with approved authorizations .", "detailed_description": "Information flow control regulates where information can travel within a system and  between\nsystems (versus who can access the information) and without explicit regard to subsequent\naccesses to that information. Flow con trol res trictions include  the following: keeping export -\ncontrolled information from being transmitted in the clear to the Internet; blocking outside traffic\nthat claims to be from within the organization; restricting requests to the Internet that are not\nfrom the internal web proxy server; and limiting information transfers between organizations\nbased on data structures and content.\nOrganizations commonly use  information flow control policies and enforcement mechanisms to\ncontrol the flow of information between designated sources and destinations (e.g., networks,\nindividuals, and devices) within systems and between interconnected systems. Flow control is\nbased on characteristics of the information or the information path. Enforcement occurs in\nboundary prote ction devices (e.g., gateways, routers, guards, encrypted tunnels, firewalls) that\nemploy rule sets or establish configuration settings that restrict system services, provide a packet -\nfiltering capability based on header information, or message -filtering c apability based on message\ncontent (e.g., implementing key word searches or using document characteristics). Organizations\nalso consider the trustworthiness of filtering and inspection mechanisms (i.e., hardware, firmware, and software components) that are  critical to information flow enforcement.\nTransferring information between systems representing different security domains with different\nsecurity policies introduces risk that such transfers violate one or more domain security policies.\nIn such  situation s, information owners or stewards provide guidance at designated policy\nenforcement points between interconnected systems. Organizations consider mandating specific\narchitectural solutions when required to enforce specific security policies. Enforcement includes :\nprohibiting information transfers between interconnected systems (i.e., allowing access only);\nemploying hardware mechanisms to enforce one -way information flows; and implementing\ntrustworthy regrading mechanisms to reassign security attributes and security labels.\n3.1.4\nSeparate the duties of individuals to reduce the risk of malevolent activity without collusion.\nSeparation of duties addresses the potential for abuse of authorized privileges and helps to reduce\nthe risk of malevolent activity without collusion. Separation of duties includes dividing mission\nfunctions and system support functions among different individuals or roles; conducting system\nsupport functions with different individuals (e.g., conf iguration management, quality assurance\nand testing, system management, programming, and network security); and ensuring that security personnel administering access control functions do not also administer audit functions. Because\nseparation of duty violations can span systems and application domains, organizations consider\nthe entirety of organizational systems and system components when developing policy on\nseparation of duties."}, "3.1.5": {"brief_description": "Employ the principle of least privilege, incl uding for specific se curity functions and privileged accounts .", "detailed_description": "Organizations employ the principle of least privilege for specific duties and authorized accesses for\nusers and processes. The principle of least privilege is applied with the goal of authorized privileges\nno higher than necessary to accomplish required or ganizational missions or business functions.\nOrganizations consider the creation of additional processes, roles, and system accounts as\nnecessary, to achieve least privilege. Organizations also apply least privilege to the development, implementation, and operation of organizational systems. Security functions include establishing\nsystem accounts, setting events to be logged, setting intrusion detection parameters, and\nconfiguring access authorizations (i.e., permissions, privileges).\nPrivileged accounts, i ncluding super user accounts, are typically described as system administrator\nfor various types of commercial off- the-shelf operating systems. Restricting privileged accounts to\nspecific personnel or roles prevents day -to-day users from having access to privileged information\nor functions. Organizations may differentiate in the application of this requirement between\nallowed privileges for local accounts and for domain accounts provided organizations retain the\nability to control system configurations for k ey security parameters and as otherwise necessary to\nsufficiently mitigate risk.\n3.1.6\nUse non- privileged accounts or roles  when accessing nonsecurity functions .\nThis requirement limits exposure when operating from within privileged accounts or roles. The\ninclusion of roles addresses situations where organizations implement access control policies such\nas role -based access control and where a change of role provides the same degree of assurance in\nthe change of acces s authorizations for the user and all processes acting on behalf of the user as\nwould be provided by a change between a privileged and non- privileged account."}, "3.1.7": {"brief_description": "Prevent non -privileged users from executing privileged functions  and capture  the execution of such functions  in audit logs .", "detailed_description": "Privileged functions include  establishing system accounts, performing system integrity checks,\nconducting patching operations, or administering cryptographic key management activities. Non-\nprivileged users are individuals that do not possess appropriate authorizations. Circumventing\nintrusion detection and prevention mechanisms or malicious code protection mechanisms are\nexamples of privileged functions that require protection from non -privileged users. Note that this\nrequirement represents a condition to be achieved by the definition of authorized privileges in 3.1.2\n.\nMisuse of privileged functions, either intentionally or unintentionally by authorized users, or by unauthorized external entities that have compromised system accounts, is a serious and ongoing\nconcern and can have significant adverse impacts on organizations. Logging the use of privileged\nfunctions is one way to detect such misuse, and in doing so, help mitigate the risk from insider\nthreats and the advanced persistent threat.\n3.1.8\nLimit un successful logon attempts.\nThis requirement applies regardless of whether the logon occurs via a local or network connection.  Due to the potential for denial of service, automatic lockouts initiated by systems are, in most\ncases, temporary and automatically release after a predeter mined period established by the\norganization (i.e., a delay algorithm). If a delay algorithm is selected, organizations may employ\ndifferent algorithms for different system components based on the capabilities of the respective\ncomponents. Responses to uns uccessful logon attempts may be implemented at the operating\nsystem and application levels."}, "3.1.9": {"brief_description": "Provide privacy and security notices consistent with applicable CUI rules.", "detailed_description": "System use notifications can be implemented usin g messages or warning banners displayed before\nindividuals log in to organizational systems. System use notifications are used only for access via\nlogon interfaces with human users and are not required when such human interfaces do not exist.\nBased on a ri sk assessment, organizations consider whether a secondary system use notification is\nneeded to access applications or other system resources after the initial network logon. Where necessary, posters or other printed materials may be used in lieu of an automated system banner.\nOrganizations consult with the Office of General Counsel for legal review and approval of warning\nbanner content.\n3.1.10\nUse session lock with pattern -hiding displays to prevent access  and viewing of data after  a\nperiod of inactivity.\nSession locks are temporary actions taken when users stop work and move away from the\nimmediate vicinity of the system but do not want to log out because of the temporary nature of their absences. Session locks are implemented where session activities can be determined,\ntypically at the operating system level (but can also be at the application level). Session locks are\nnot an acceptable substitute for logging out of the system, for example, if organizations require\nusers to log out at the end of the workday.\nPattern -hiding displays can include static or dynamic images, for example, patterns used with\nscreen savers, photographic images, solid colors, clock, battery life indicator, or a blank screen,\nwith the additional caveat that none of the images convey controlled unclassified information.\n3.1.11\nTerminate  (automatically) a user  session a fter a defined condition.\nThis requirement addresses the termination of user- initiate d logical sessions in contrast to the\ntermination of network connections that are associated with communications sessions (i.e.,\ndisconnecting from the network). A logical session (for local, network, and remote access) is\ninitiated whenever a user (or pro cess acting on behalf of a user) accesses an organizational system.\nSuch user sessions can be terminated (and thus terminate user access) without terminating\nnetwork sessions. Session termination terminates all processes associated with a user\u2019s logical\nsession except those processes that are specifically created by the user (i.e., session owner) to\ncontinue after the session is terminated. Conditions or trigger events requiring automatic session\ntermination can include  organization -defined periods of user inactivity, targeted responses to\ncertain types of incidents, and time -of-day restrictions on system use."}, "3.1.12": {"brief_description": "Monitor and control  remote access sessions.", "detailed_description": "Remote access is access to organizational systems by users (or processes acting on behalf of users)\ncommunicating through external networks (e.g., the Internet). Remote access methods include\ndial-up, broadband, and wireless. Organizations often employ encrypted virtual private networks\n(VPNs) to enhance confident iality over remote connections. The use of encrypted VPNs does not\nmake the access non -remote; however, the use of VPNs, when adequately provisioned with\nappropriate control  (e.g., employing encryption techniques for confidentiality protection), may\nprovid e sufficient assurance to the organization that it can effectively treat such connections as\ninternal networks. VPNs with encrypted tunnels can affect the capability to adequately monitor\nnetwork communications traffic for malicious code.\nAutomated monitor ing and control of remote access sessions allows organizations to detect cyber-\nattacks and help to ensure ongoing compliance with remote access policies by auditing connection activities of remote users on a variety of system components (e.g., servers, wor kstations, notebook\ncomputers, smart phones, and tablets).\n[SP 800- 46], [SP 800 -77], and [ SP 800- 113\n] provide guidance on secure remote access and virtual\nprivate networks."}, "3.1.13": {"brief_description": "Employ cryptographic mechanisms to protect the confidentiality of remote a ccess sessions.", "detailed_description": "Cryptographic standards include FIPS- validated cryptography and NSA- approved cryptography.\nSee [NIST CRYPTO ]; [NIST CAVP ]; [NIST CMVP ]; National Security Agency  Cryptographic Standards."}, "3.1.14": {"brief_description": "Route remote access via managed  access control points.", "detailed_description": "Routing remote access through managed access control points enhances explicit, organizational\ncontrol over such connections, reducing the susceptibility to unauthorized access to organizational\nsystems resulting in the unauthorized disclosure of CUI."}, "3.1.15": {"brief_description": "Authorize  remote execution of privileged commands and remote access to security -relevant information .", "detailed_description": "A privileged command is a human -initiated (interactively or via a process operating on behalf of\nthe human) command executed on a system involving the control, monitoring, or administration\nof the system including security functions and associated security- relevant information. Security -\nrelevant information is any information within the system that can potentially impact the\noperation of security functions or the provision of security services in a manner that could result\nin failure to enforce the system security policy or maintain isolation of co de and data. Privileged\ncommands give individuals the ability to execute sensitive, security -critical, or security -relevant\nsystem functions. Controlling such access from remote locations helps to ensure that unauthorized\nindividuals are not able to execut e such commands freely with the potential to do serious or\ncatastrophic damage to organizational systems. Note that the ability to affect the integrity of the system is considered security -relevant as that could enable the means to by -pass security functio ns\nalthough not directly impacting the function itself.\n3.1.16\nAuthorize wireles s access prior to allowing such connections.\nEstablishing usage restrictions and configuration/connection requirements for wireless access to the system provides criteria for organizations to support wireless access authorization decisions.\nSuch restrictions and requirements reduce the susceptibility to unauthorized access to the system\nthrough wireless technologies. Wireless networks use authentication protocols which provide\ncredential protection and mutual authentication.\n[SP 800- 97\n] provide guidance on secure wireless networks."}, "3.1.17": {"brief_description": "Protect wireless access using authentic ation and encryption.", "detailed_description": "Organizations authenticate individuals and devices to help protect wireless access to the system.\nSpecial attention is given to the wide variety of devices that are part of the Internet of Things with\npotential wireless access to organizational systems.  See [NIST CRYPTO ]."}, "3.1.18": {"brief_description": "Control conn ection of mobile devices.", "detailed_description": "A mobile device is a computing device that has a small form factor such that it can easily be carried\nby a single individual; is designed to operate without a physical connection (e.g., wirelessly\ntransmit or receive information); possesses local, non -removable or removable data storage; and\nincludes a self -contained power sou rce. Mobile devices may also include voice communication\ncapabilities, on -board sensors that allow the device to capture information, or built- in features for\nsynchronizing local data with remote locations. Examples of mobile devices include smart phones,\ne-readers, and tablets.\nDue to the large variety of mobile devices with different technical characteristics and capabilities,\norganizational restrictions may vary for the different types of devices. Usage restrictions and\nimplementation guidance for mobile  devices include: device identification and authentication;\nconfiguration management; implementation of mandatory protective software (e.g., malicious\ncode detection, firewall); scanning devices for malicious code; updating virus protection software;\nscanning for critical software updates and patches; conducting primary operating system (and\npossibly other resident software) integrity checks; and disabling unnecessary hardware (e.g.,\nwireless, infrared). The need to provide adequate security for mobile devices goes beyond this requirement. Many controls  for mobile devices are reflected in other CUI security requirements.\n[SP 800- 124\n] provides guidance on mobile device security."}, "3.1.19": {"brief_description": "Encrypt CUI on mobile devices  and mobile computing platforms .23", "detailed_description": "Organizations can employ  full-device encryption or container -based encryption to protect the\nconfidentiality of CUI on mobile devices and computing platforms. Container -based encryption\nprovides a more fine -grained approach to the encryption of data and information including\nencrypting selected data structures such as files, records, or fields.  See [NIST CRYPTO ]."}, "3.1.20": {"brief_description": "Verify and control /limit connections to and use of external systems.", "detailed_description": "External systems are systems or components of systems for which organizations typically have no direct supervision and authority over the applicat ion of security requirements and controls or the\ndetermination of the effectiveness of implemented controls  on those systems. External systems\ninclude  personally owned systems, components,  or devices and privately -owned computing and\ncommunications devices resident in commercial or public facilities. This requirement also\naddresses the use of external systems for the processing, storage, or transmission of CUI, including\naccessing cloud services (e.g., infrastructure as a service, plat form as a service, or software as a\nservice) from organizational systems.\nOrganizations establish terms and conditions for the use of external systems in accordance with\norganizational security policies and procedures. Terms and conditions address as a min imum, the\ntypes of applications that can be accessed on organizational systems from external systems. If\n23 Mobile devices and computing platforms include, for  example, smartphones and tablets .\nterms and conditions with the owners of external systems cannot be established, organizations\nmay impose restrictions on organizational personnel using  those external systems.\nThis requirement recognizes that there are circumstances where individuals using external systems\n(e.g., contractors, coalition partners) need to access organizational systems. In those situations,\norganizations need confidence tha t the external systems contain the necessary controls so as not\nto compromise, damage, or otherwise harm organizational systems. Verification that the required controls  have been effectively implemented can be achieved  by third- party, independent\nassessmen ts, attestations, or other means, depending on the assurance or confidence level\nrequired by organizations.\nNote that while \u201cexternal\u201d typically refers to outside of the organization\u2019s direct supervision and authority, that is not always the case.  Regarding the protection of CUI across an organization, the\norganization may have systems that process CUI and others that do not. And among the systems\nthat process CUI there are likely access restrictions for CUI that apply between systems. Therefore,\nfrom the p erspective of a given system, other systems within the organization may be considered\n\u201cexternal\" to that system.\n3.1.21\nLimit use of portable storage devices on external systems.\nLimits on the use of organization -controlled portable storage devices in external systems include\ncomplete prohibition of the use of such devices or restrictions on how the devices may be used\nand under what conditions the devices may be used. Note that while \u201cexternal\u201d typica lly refers to\noutside of the organization\u2019s direct supervision and authority, that is not always the case.\nRegarding the protection of CUI across an organization, the organization may have systems that\nprocess CUI and others that do not. Among the systems that process CUI there are likely access\nrestrictions for CUI that apply between systems. Therefore, from the perspective of a given system,\nother systems within the organization may be considered \u201cexternal\" to that system."}, "3.1.22": {"brief_description": "Control CUI posted or processed on publicly access ible systems .", "detailed_description": "In accordance with laws, Executive Orders, directives, policies, regulations, or standards, the public\nis not authorized access to nonpublic information (e.g., information protected under the Privacy\nAct, CUI, and proprietary information). This requirement addresses systems that are controlled by\nthe organization and accessible to the public, typically without identification or authentication.\nIndividuals authori zed to post CUI onto publicly accessible systems are designated. The content of\ninformation is reviewed prior to posting onto publicly accessible systems to ensure that nonpublic\ninformation is not included."}}}, "3.2": {"title": "AWARENESS  AND  TRAINING", "sections": {"3.2.1": {"brief_description": "Ensure that  managers , systems administrators, and users of organizational systems are made aware of the security risks associated with their activities and of the applicable policies, standards, and procedures related to the security of those systems.", "detailed_description": "Organizations determine the content and frequency of security awareness training and security\nawareness techniques based on the specific organizational requirements and the systems to which\npersonnel have authorized access. The content includes a basic understanding of the need for\ninformation security and user actions to maintain security and to respond to suspected security\nincidents. The content also addresses awareness of the need for operations security. Security\nawareness techniques include: formal tr aining;  offering supplies in scribed with security reminders;\ngenerating email advisories or notices from organizational offic ials; displaying logon screen\nmessages; displaying security awareness posters;  and conducting information security awareness\nevents .\n[SP 800- 50] provides guidance on security awareness and training programs."}, "3.2.2": {"brief_description": "Ensure that personnel are trained to carry out their assigned information security -related duties and responsibilities.", "detailed_description": "Organizations determine the content and frequency of security training based on the assigned duties, roles, and responsibilities of individuals and the security requirements of organizations and\nthe systems to which personnel h ave authorized access. In addition, organizations provide system\ndevelopers, enterprise architects, security architects, acquisition/procurement offici als, software\ndevelopers, system developers, systems integrators, system/ network administrators, personne l\nconducting configuration management and auditing activities, personnel performing independent verifi cation and validation , security assessors, and other personnel having access to system -level\nsoftware, security -related technical training specifically ta ilored for their assigned duties.\nComprehensive role- based training addresses management, operational, and technical roles and\nresponsibilities covering physical, personnel, and technical controls . Such tra ining can include\npolicies, procedures, tools, and  artifacts for the security roles defined. Organizations also provide\nthe training necessary for individuals to carry out their responsibilities related to operations and\nsupply chain security within the context of organizational information security progr ams.\n[SP 800- 181] provides guidance on role -based information security training in the workplace.  [\nSP\n800-161] provides guidance on supply chain risk management.\nDerived Security Requirements"}, "3.2.3": {"brief_description": "Provide security awareness training on recognizing and reporting potential indicators of insider threat .", "detailed_description": "Potential indicators  and possible precursors of insider threat include behaviors such as: inordinate,\nlong -term job dissatisfaction; attempts to gain access to information that is not required for job\nperformance; unexplained access to financial resources; bullying or sexual harassment of fellow\nemployees; workplace violence; and other serio us violations of the policies, procedures, directives,\nrules, or practices  of organizations . Security awareness training includes how to communicate\nemployee and management concerns regarding potential indicators of insider threat through\nappropriate organizational channels in accordance with established organizational policies and\nprocedures. Organizations may consider tailoring insider threat awareness topics to the role (e.g.,\ntraining for managers may be focused on specific changes in behavior of team members, while\ntraining for employees may be focused on more general observations)."}}}, "3.3": {"title": "AUDIT  AND  ACCOUNTABILITY", "sections": {"3.3.1": {"brief_description": "Create and retain system audit logs and records to the extent needed to enable the monitoring, analysis, investigation, and reporting of unlawful or unauthorized system activity.", "detailed_description": "An event is any observable occurrence in a system, which includes unlaw ful or unauthorized\nsystem activity. Organizations identify event types for which a logging functionality is needed as\nthose events which are significant and relevant to the security of systems and the environments\nin which those systems operate to meet sp ecific and ongoing auditing needs. Event types can\ninclude password changes, failed logons or failed accesses related to systems, administrative\nprivilege usage, or third -party credential usage. In determining event types that require logging,\norganization s consider the monitoring and auditing appropriate for each of the CUI security\nrequirements. Monitoring and auditing requirements can be balanced with other system needs.\nFor example, organizations may determine that systems must have the capability to log every file\naccess both successful and unsuccessful, but not activate that capability except for specific\ncircumstances due to the potential burden on system performance.\nAudit records can be generated at various levels of abstraction, including at the pa cket level as\ninformation traverses the network. Selecting the appropriate level of abstraction is a critical aspect\nof an audit logging capability and can facilitate the identification of root causes to problems.\nOrganizations consider in the definition o f event types, the logging necessary to cover related\nevents such as the steps in distributed, transaction -based processes (e.g., processes that are\ndistributed across multiple organizations) and actions that occur in service -oriented or cloud -\nbased archit ectures.\nAudit record content that may be necessary to satisfy this req uirement includes time stamps,\nsource and destination addresses, user or process identifiers, event descript ions, success or fail\nindications, filenames involved, and access control or flow control rules invoked. Event outcomes\ncan include indicators of event success or failure and event -specific results (e.g., the security state\nof the system after the event occurred).\nDetailed information that organizations may consider in audit record s includes  full text recording\nof privileged commands or the individual identities of group account users. Organizations consider limiting the additional audit log information to only that information explicitly needed for specific\naudit requirements. This  facilitates the use of audit trails and audit logs by not including\ninformation that could potentially be misleading or could make it more difficult to locate\ninformation of interest. Audit logs are reviewed and analyzed as often as needed to provide\nimpo rtant information to organizations to facilitate risk- based decision making.\n[SP 800- 92\n] provides guidance on security log management."}, "3.3.2": {"brief_description": "Ensure that the actions of individual system users can be uniquely traced to those users,  so they can be held accountable for their actions.", "detailed_description": "This requirement ensures that the contents of the audit record include the information needed to\nlink the audit event to the actions of an individual to the extent feasible. Organizations consider\nlogging for trace ability including results from monitoring of account usage, remote access, wireless\nconnectivity, mobile device connection, communications at sy stem boundaries, configuration\nsettings, physical access, nonlocal maintenance, use of maintenance tools, temperature and\nhumidity, equipment delivery and removal, system component i nventory, use of mobile code, and\nuse of  Voice over Internet Protocol  (VoIP).\nDerived Security Requirements"}, "3.3.3": {"brief_description": "Review  and update logged  events.", "detailed_description": "The intent of this requirement is to period ically re -evaluate which logged events will continue to\nbe included in the list of e vents to be logged. T he event types that are logged by organizations may\nchange  over time . Reviewing and updating the set of logged event types periodically is necessary\nto ensure that the current set remains necessary and sufficient."}, "3.3.4": {"brief_description": "Alert in the event of  an audit logging process failure.", "detailed_description": "Audit logging process  failures include software and hardware errors, failures in the audit record\ncapturing mechanisms, and audit record storage capacity being reached or exceeded. This\nrequirement applies to each audit record data storage repository (i.e., distinct system component\nwhere audit records are stored), the total audit record storage capacity of organizations (i.e., all\naudit record data storage repositories combined), or both ."}, "3.3.5": {"brief_description": "Correlate audit record  review, analysis, and reporting processes for investigation and response to indications of  unlawful, unauthorized , suspicious, or unusual activity.", "detailed_description": "Correlating audit record review, analysis, and reporting processes helps to ensure that they do not\noperate independently, but rather collectively. Regarding the assessment of a given organizational\nsystem, the requirement is agnostic as to whether this correlation is applied at the syste m level or\nat the organization level across all systems."}, "3.3.6": {"brief_description": "Provide  audit record reduction and  report generation to support on -demand analysis and reporting.", "detailed_description": "Audit record reduction is a process that manipulates collected audit information and organizes\nsuch information in a summary format that is more meaningful to analysts. Audit record reduction\nand report generation capabilities do not always emanate from the same system or organizational\nentities conducting auditing activities. Audit record reduction capability can include, for example,\nmodern data mining techniques with advanced data filters to identify anomalous behavior in audit records. The report generation capability provided by the system ca n help generate customizable\nreports. Time ordering of audit records can be a significant issue if the granularity of the time stamp\nin the record is insufficient.\n3.3.7\nProvide a system capability that compares and synchronizes internal system clocks with an\nauthoritative source to generate time stamps for audit records .\nInternal system clocks are used to generate time stamps, which include date and time. Time is\nexpress ed in Coordinated Universal Time (UTC), a modern continuation of Greenwich Mean Time\n(GMT), or local time with an offset from UTC. The granularity of time measurements refers to the degree of synchronization between system clocks and reference clocks, for example, clocks\nsynchronizing within hundreds of milliseconds or within tens of milliseconds. Organizations may\ndefine different time granularities for different system components. Time service can also be\ncritical to other security capabilities such as ac cess control and identification and authentication,\ndepending on the nature of the mechanisms used to support those capabilities. This requirement\nprovides uniformity of time stamps for systems with multiple system clocks and systems connected\nover a netwo rk. See [IETF 5905\n]."}, "3.3.8": {"brief_description": "Protect audit information and audit logging tools from unauthorized acc ess, modification , and deletion .", "detailed_description": "Audit information  includes all information (e.g., audit records, audit log settings, and audit reports)\nneeded to successfully audit system activity. Audit logging tools are those programs and devices\nused to conduct audit and logging activities. This requirement focuses o n the technical protection\nof audit information and limits the ability to access and execute audit logging tools to authorized\nindividuals. Physical protection of audit information is addressed by media protection and physical\nand environmental protection requirements."}, "3.3.9": {"brief_description": "Limit management of audit logging functionality to a subset of privileged users.", "detailed_description": "Individuals with privileged access to a system and who are also the subject of an audit by that\nsystem, may affect the reliability of audit information by inhibiting audit logging activities or\nmodifying audit records. This requirement specifies that privileged access be further defined\nbetween audit -related privileges and other privileges, thus limiting the use rs with audit -related\nprivileges."}}}, "3.4": {"title": "CONFIGURATION  MANAGEMENT", "sections": {"3.4.1": {"brief_description": "Establish and maintain baseline configurations and inventories of organizational systems (including hardware, software, firmware, and documentation) throughout the respective system development life cycles.", "detailed_description": "Baseline configurations are documented, formally reviewed, and agreed- upon specifications for\nsystems or configuration items within those systems. Baseline co nfigurations serve as a basis for\nfuture builds, releases, and changes to systems. Baseline configurations include information about\nsystem components (e.g., standard software packages installed on workstations, notebook\ncomputers, servers, network components, or mobile devices; current version numbers and update\nand patch information on operating systems and applications; and configuration settings and\nparameters), network topology, and the logical placement of those components within the system\narchitectu re. Baseline configurations of systems also reflect the current enterprise architecture.\nMaintaining effective baseline configurations requires creating new baselines as organizational\nsystems change over time. Baseline configuration maintenance includes reviewing and updating\nthe baseline configuration when changes are made based on security risks and deviations from the\nestablished baseline configuration\nOrganizations can implement centralized system component inventories that include components\nfrom mu ltiple organizational systems. In such situations, organizations ensure that the resulting\ninventories include system -specific information required for proper component accountability\n(e.g., system association, system owner). Information deemed necessary f or effective\naccountability of system co mponents includes hardware inventory specifications, software license\ninformation, software version numbers, component owners, and for networked components or\ndevices, machine names and network addresses. Inventory s pecifications include manufacturer,\ndevice type, model, serial number, and physical location.\n[SP 800- 128] provides guidance on security -focused configuration management ."}, "3.4.2": {"brief_description": "Establish and enforce security configuration settings for information technology products employed in organizational systems.", "detailed_description": "Configuration settings are the set of parameters that can be changed in hardware, software, or\nfirmware components of the system that  affect the security posture or functionality of the system.\nInformation technology products for which security -related configuration settings can be defined\ninclude  mainframe computer s, servers, workstations, input and output devices (e.g., scanners,\ncopi ers, and printers), network components (e.g., firewalls, routers, gateways, vo ice and data\nswitches, wireless access points, network appliances, sensors), operating systems, middleware,\nand applications.\nSecurity parameters are those parameters impacting t he security state of systems including the\nparameters required to satisfy other security requirements. Security parameters includ e: registry\nsettings; account, file, directory permission settings; and settings for functions, ports, protocols, and remote connections. Organizations establish organization -wide configuration settings and\nsubsequently derive specific configuration settings for systems. The established settings become\npart of the systems configuration baseline.\nCommon secure configurations (also referred to as security configuration checklists, lockdown and\nhardening guides, security reference guides, security technical implementation guides) provide\nrecognized, standardized, and established benchmarks that stipulate secure co nfiguration settings\nfor specific information technology platforms/products and instructions for configuring those\nsystem components to meet operational requirements. Common secure configurations can be developed by a variety of organi zations including inf ormation technology product developers,\nmanufacturers, vendors, consortia, academia, industry, federal agencies, and other organizations\nin the public and private sectors.\n[SP 800- 70] and [ SP 800- 128\n] provide guidance on security configuration settings.\nDerived Security Requirements"}, "3.4.3": {"brief_description": "Track, review, approve or disapprove, and log  changes to organizational systems.", "detailed_description": "Tracking, reviewing, approving/disapproving, and logging changes is called configuration change\ncontrol. Configuration change control for organizational systems involves the systematic proposal, justification, implementation, testing, review, and disposition of changes to the systems, including\nsystem upgrades and modifications. Configuration change control includes changes to baseline\nconfigurations for components and configuration items of systems, changes to configuration\nsettings for information technology products (e.g., o perating systems, applications, firewalls,\nrouters, and mobile devices), unscheduled and unauthorized changes, and changes to remediate\nvulnerabilities.\nProcesses for managing configuration changes to systems include  Configuration Control Boards or\nChange Advisory Boards that review and approve proposed changes to systems. For new\ndevelopment systems or systems undergoing major upgrades, organizations consider including\nrepresentatives from development organizations on the Configuration Control Boards or Ch ange\nAdvisory Boards. Audit logs of changes include activities before and after changes are made to\norganizational systems and the activities required to implement such changes.\n[SP 800- 128\n] provides guidance on configur ation change control."}, "3.4.4": {"brief_description": "Analyze the security impact of changes prior to implementation.", "detailed_description": "Organizational personnel with information security responsibilities (e.g., system administrators,\nsystem security officers, system security managers, and systems security engineers) conduct\nsecurity impact analyses. Individuals conducting security impact analyses possess the necessary\nskills and technical expertise to analyze the changes to systems and the associated security\nramifications. Security impact ana lysis may include reviewing security plans to understand security\nrequirements and reviewing system design documentation to understand the implementation of\ncontrols  and how specific cha nges might affect the contr ols. Security impact analyses may also\ninclude risk assessments to better understand the impact of the changes and to de termine if\nadditional controls  are required.\n[SP 800- 128] provides guidance on configuration change control and security impact analysis."}, "3.4.5": {"brief_description": "Define, document, approve, and enforce physical and logical access restrictions  associated with changes to organizational system s.", "detailed_description": "Any changes to the hardware, software, or firmware components of systems can potentially have\nsignificant effects on the overall security of the systems. Therefore, organizations permit only qualified and authorized individuals to access systems for purposes of initiating changes, inc luding\nupgrades and modifications. Access restrictions for change also include software libraries.\nAccess res trictions include physical and logical access control requirements, workflow automation,\nmedia libraries, abstract layers (e.g., changes implemente d into external interfaces rather than\ndirectly into systems), and change windows (e.g., changes occur only during certain specified\ntimes). In addition to security concerns, commonly- accepted due diligence for configuration\nmanagement includes access rest rictions as an essential part in ensuring the ability to effectively\nmanage the configuration.\n[SP 800- 128\n] provides guidance on configuration change control."}, "3.4.6": {"brief_description": "Employ the principle of least functionality by configuring organizational system s to provi de only essential capabilities .", "detailed_description": "Systems can provide a wide variety of functions and services. Some of the functions and services routinely provided by defa ult, may not be necessary to support essential organizational missions,\nfunctions, or operations. It is sometimes convenient to provide multiple services from single system components . However,  doing so increases risk over limiting the services provided by  any\none component. Where feasible, organizations limit component functionality to a single function\nper component.\nOrganizations review functions and services provided by systems or components of systems, to\ndetermine which functions and services are candidates for elimination. Organizations disable\nunused or unnecessary physical and logical ports and protocols to prevent unauthorized\nconnection of devices, transfer of information, and tunneling. Organizations can utilize network\nscanning tools, intrus ion detection and prevention systems, and end- point protections such as\nfirewalls and host -based intrusion detection systems to identify and prevent the use of prohibited\nfunctions, ports, protocols, and services.\n3.4.7\nRestrict, d isable, or prevent  the use of nonessential programs, functions, ports, protocols , and\nservices.\nRestricting the use of nonessential software (p rograms) includes restricting the roles allowed to\napprove program execution; prohibiting auto -execute; program blacklisting and whitelisting; or\nrestricting the number of program instances executed at the same time. The organization makes\na security -based determination whi ch functions, ports, protocols, and/or services are restricted.\nBluetooth, File Transfer Protocol ( FTP) , and peer -to-peer networking are examples of protocols\norganizations consider preventing the use of, restricting, or disabling."}, "3.4.8": {"brief_description": "Apply  deny -by-exception (blacklisting ) policy to prevent the use of unauthorized software  or deny -all, permit- by-exception (whitelisting) policy to allow the execution of authorized software .", "detailed_description": "The process used to identify software programs that are not authorized to execute on systems is\ncommonly referred to as blacklisting. The process used to identify software programs that are\nauthorized to execute on systems is commonly referred to as whitelisting. Whitelisting is the\nstronger of the two policies for restricting software program execution. In addition to whitelisting,\norganizations consider verifying the integrity of whitelisted software programs using, for example,\ncryptographic checksums, digital signatures, or hash fu nctions. Verification of whitelisted software\ncan occur either prior to execution or at system startup.\n[SP 800- 167] provides guidance on application whitelisting."}, "3.4.9": {"brief_description": "Control and monitor user -installed software.", "detailed_description": "Users can  install software in organizational systems if provided the necessary privileges. To\nmaintain control over the software installed, organizations identify permitted and prohibited actions regarding software installation through policies. Permitted software inst allations include\nupdates and security patches to existing software and applications from organization -approved\n\u201capp stores.\u201d Prohibited software installa tions may include software with unknown or suspect\npedigrees or software that organizations consid er potentially malicious. The policies organizations\nselect governing user -installed software may be organization -developed or provided by some\nexternal entity. Policy enforcement methods include procedural methods, automated methods, or\nboth."}}}, "3.5": {"title": "IDENTIFICATION  AND  AUTHENTICATION", "sections": {"3.5.1": {"brief_description": "Identify system users, processes acting on behalf of users, and devices.", "detailed_description": "Common device id entifiers include Media Access Control (MAC), Internet P rotocol (IP) addresses,\nor device- unique token identifiers. Management of individual identifiers is not applicable to shared\nsystem accounts. Typically, individual identifiers are the user names associated with the system\naccounts a ssigned to those individuals. Organizations may require unique identification of\nindividuals in group accounts or for detailed accountability of individual activity. In addition, this\nrequirement addresses individual identifiers that are not necessarily associated with system\naccounts. Organizational devices requiring identification may be defined by type, by device, or by a combination of type/device.\n[SP 800- 63-3\n] provides guidance on digital identities."}, "3.5.2": {"brief_description": "Authenticate (or verify) the identities of users, processes, or devices, as a prerequisite to allowing access to organizational systems.", "detailed_description": "Individual authe nticators include the following: passwords, key cards, cryptographic devices, and\none-time password devices. Initial authenticator content is the actual content of the authenticator,\nfor example, the initial password. In contrast, the requirements about authenticator content\ninclude the minimum password length . Developers ship system components with factory default\nauthentication credentials to allow for initial installation and configuration. Default authentication\ncredentials are often well known, easily discoverable, and present a significant security risk.\nSystems support authenticator management by organization- defined settings and restrictions for\nvarious authenticator characte ristics including minimum password length, validation time window\nfor time synchronous one -time tokens, and number of allowed rejec tions during the verification\nstage of biometric authentication. Authenticator management includes issuing and revoking, when\nno longer needed, authenticators for temporary access such as that required for remote maintenance. Device authe nticators include certificates and passwords.\n[SP 800- 63-3\n] provides guidance on digital identities.\nDerived Security Requirements"}, "3.5.3": {"brief_description": "Use multifactor authentication for local  and network access to privileged accounts and for network access to non -privileged accounts .24 25", "detailed_description": "Multifactor authentication requires the use of two or more different factors to authenticate. The factors are defined as something you know (e.g., password, personal identification number [PIN]);\nsomething you have (e.g., cryptographic identification device, token); or something you are (e.g.,\nbiometric). Multifactor authentication solutions that feature physical authe nticators include\nhardware authenticators providing time -based or challenge -response authenticators and smart\ncards. In addition to authentic ating users at the system level (i.e., at logon), organizations may also\nemploy authentication mechanisms at the application level, when necessary, to provide increased\ninformation security.\nAccess to organizational systems is defined as local access or ne twork access. Local access is any\naccess to organizational systems by users (or processes acting on behalf of users) where such\naccess is obtained by direct connections without the use of networks. Network access is access to\nsystems by users (or processes acting on behalf of users) where such access is obtained through\nnetwork connections (i.e., nonlocal accesses). Remote access is a type of network access that\ninvolves communication th rough external networks. The use of encrypted virtual private networks\nfor\nconnections between or ganization -controlled and non -organization controlled en dpoints may\nbe treated as  internal networks with regard to protecting the confidentiality of in formation .\n24 Multifactor authentication  requires two or more different factors to achieve authentication. The factors include:\nsomething you know (e.g., password/PIN); something you have (e.g., cryptographic identification device, token); or\nsomething you are (e.g., biometric). The requirement for multifactor authentication should not be interpre ted as\nrequiring federal Personal Identity Verification (PIV) card or Department of Defense Common Access Card (CAC) -like\nsolutions. A variety of multifactor solutions (including those with replay resistance) using tokens and biometrics are commercially available. Such solutions may employ hard tokens (e.g., smartcards, key fobs, or dongles) or soft tokens to store user credentials.\n25 Local access  is any access to a system by a user (or process acting on behalf of a user) communicating through a\ndirect connection without the use of a network. Network access  is any access to a system by a user (or a process\nacting on behalf of a user) communicating through a network (e.g., local area network, wide area network, Internet).\n[SP 800- 63-3] provides guidance  on digital identities."}, "3.5.4": {"brief_description": "Employ replay -resistant authentication mechanisms for network access to privileged and non- privileged accounts .", "detailed_description": "Authentication processes resist replay attacks if it is impractical to successfully authenticate by\nrecording or replaying previous authentication messages. Replay- resistant t echniques include\nprotocols that use nonces or challenges such as time synchronous or challenge -response one- time\nauthenticators.\n[SP 800- 63-3] provides guidance on digital identities."}, "3.5.5": {"brief_description": "Prevent reuse of i dentifiers for a defined period.", "detailed_description": "Identifiers are provided for users, processes acting on behalf of users, o r devices ( 3.5.1 ). Preventing\nreuse of identifiers implies preventing the assignment of previously used individual, group, role, or\ndevice identifiers to different individuals, groups, roles, or devices."}, "3.5.6": {"brief_description": "Disable identifiers after a defined period of inactivity.", "detailed_description": "Inactive identifiers pose a risk to organizational information because attackers may exploit an\ninactive identifier to gain undetected access to organizational devices. The owners of the inactive\naccounts may not notice if unauthorized access to the account has been obtained."}, "3.5.7": {"brief_description": "Enforce  a minimum password complexity and change of characters w hen new passwords are created .", "detailed_description": "This requirement applies to single -factor authentication of individuals using passwords as\nindividual or group authenticators, and in a similar manner, when passwords are used as part of multifactor authenticators. The number of changed characters refers to the number of changes\nrequired with respect to the total number of positions in the current password. To mitigate certain\nbrute force attacks against passwords, organizations may also consider salting passwords.\n3.5.8\nProhibit password reuse for a sp ecified number of generations.\nPassword lifetime restrictions do not apply to temporary passwords."}, "3.5.9": {"brief_description": "Allow temporary password use for system logons with an immediate chan ge to a  permanent password.", "detailed_description": "Changing temporary passwords to permanent passwords immediately after system logon ensures\nthat the necessary strength of the authentication mechanism is implemented at the earliest\nopportunity, reducing the susceptibility t o authenticator compromises."}, "3.5.10": {"brief_description": "Store  and transmit only cryptographically -protected passwords.", "detailed_description": "Cryptographically -protected passwords use salted one -way cryptographic hashes of passwords.\nSee [NIST CRYPTO ]."}, "3.5.11": {"brief_description": "Obscure  feedback of authentication information .", "detailed_description": "The feedback from systems does not provide any information that would allow unauthorized\nindividuals to compromise authentication mechanisms. For some types of systems or system\ncomponents, for example, desktop or notebook computers with relatively large monitors, the\nthreat (often referred to as shoulder surfing) may be significant. For other types of syste ms or\ncomponents, for example, mobile devices with small displays, this threat may be less significant,\nand is balanced against the increased likelihood of typographic input errors due to the small\nkeyboards. Therefore, the means for obscuring the authenti cator feedback is selected accordingly.\nObscuring authenticator feedba ck includes displaying asterisks when users ty pe passwords into\ninput devices  or displaying feedback for a very limited time before fully obscuring it."}}}, "3.6": {"title": "INCIDENT  RESPONSE", "sections": {"3.6.1": {"brief_description": "Establish an operational incident -handling capability for organizational  systems that includes preparation, detection, analysis, containment, recovery, and  user response activities.", "detailed_description": "Organizations recognize that incident handling capability is dependent on the capabilities of\norganizational systems and the mission/business processes being supported by those systems.\nOrganizations consider incident handling as part of the definition, design, and development of\nmission/business processes and systems. Incident -related information can be obtained from a\nvariety of sources including audit monitoring, network monitoring, physical access monitorin g,\nuser and administrator reports, and reported supply chain events. Effective incident handling capability includes coordination among many organizational entities includi ng mission/business\nowners, system owners, authorizing officials, human resources of fices, physical and personnel\nsecurity offices, legal departments, operations personnel, procurement offices, and the risk\nexecutive.\nAs part of user response activities, incident response training is provided by organizations and is\nlinked directly to the  assigned roles and responsibilities of organizational personnel to ensure that\nthe appropriate content and level of detail is included in such training. For example, regular users\nmay only need to know who to call or how to recognize an incident on the sy stem; system\nadministrators may require additional training on how to handle or remediate incidents; and\nincident responders may receive more specific training on forensics, reporting, system recovery, and restoration. Incident response training includes user training in the identification/reporting of\nsuspicious activities from external and internal sources. User response activities also includes\nincident response assistance which may consist of help desk support, assistance groups, and access\nto forensics  services or consumer redress services, when required.\n[SP 800- 61] provides guidance on incident handling. [ SP 800 -86] and [ SP 800- 101\n] provide guidance\non integrating forensic techniques into incident response.  [SP 800- 161] provides guidance on\nsupply chain risk management."}, "3.6.2": {"brief_description": "Track, document, and  report incidents to designated offic ials and/or authorities  both internal and external to the organization .", "detailed_description": "Tracking and documenting system security i ncidents includes maintaining records about each\nincident, the status of the incident, and other pertinent information necessary for forensics,\nevaluating incident details, trends, and handling. Incident information can be obtained from a\nvariety of sources including incide nt reports, incident response teams, audit monitoring, network\nmonitoring, physical access monitoring, and user/administrator reports.\nReporting incidents addresses specific incident reporting requirements within an organization and\nthe formal incident rep orting requirements for the organization. Suspected security incidents may\nalso be rep orted and include the receipt of suspicious email communications that can potentially\ncontain malicious code. The types of security incidents reported, the content and ti meliness of the\nreports, and the designated reporting authorities reflect applicable laws, Executive Orders,\ndirectives, regulations, and policies.\n[SP 800- 61] provides guidance on incident handling.\nDerived Security Requ irements"}, "3.6.3": {"brief_description": "Test the organizational incident response capability.", "detailed_description": "Organizations test incident response capabi lities to determine the effectiveness of the capabilities\nand to identify potential weaknesses or deficiencies. Incident response  testing includes the use of\nchecklists, walk -through or tabletop exercises, simulations ( both parallel and full interrupt), and\ncomprehensive exercises. Incident response testing can also include a determination of the effec ts\non organizational operations (e.g., reduction in mission capabilities), organizational assets, and\nindividuals due to incident response.\n[SP 800- 84] provides guidance on testing programs for information technology capa bilities."}}}, "3.7": {"title": "MAINTENANCE", "sections": {"3.7.1": {"brief_description": "Perform maintenance on organizational systems.26", "detailed_description": "This requirement addresses the information security aspects of the system maintenance program\nand applies to all types of maintenance to any system component (including hardware, firmware,\napplications) conducted by any local or nonlocal entity. System maintenance also includes those\ncomponents not directly associated with information processing and data or information retention\nsuch as scanners, copiers, and printers."}, "3.7.2": {"brief_description": "Provide controls on the tools, techniques, mechanisms, and personnel used to conduct system maintenance.", "detailed_description": "This requirement addresses security -related issues with maintenance tools that are not within the\norganizational system boundaries that process, store, or transmit CUI, but are used specifically for\ndiagnostic and repair actions on those systems. Organizations have flexibility in determining the\n26 In general, system maintenance requirements tend to support the security objective of availability . However,\nimproper system maintenance or a failure to perform maintenance can result in the unauthorized disclosure of CUI,\nthus compromising confidentiality  of that information.\ncontrols in place for maintenance tools, but can include approving, controlling, and monitoring the\nuse of such tools. Maintenance tools are potential vehicles for transporting malicious code, either\nintentionally or unintentionally, into a facility and i nto organizational systems. Maintenance tools\ncan include hardware, software, and firmware items, for example, hardware and software\ndiagnostic test equipment and hardware and software packet sniffers.\nDerived Security Requirements"}, "3.7.3": {"brief_description": "Ensure equipment removed for off- site maintenance is sanitized of any CUI.", "detailed_description": "This requirement  addresses the information security aspec ts of system maintenance that are\nperformed off -site and applies to all types of maintenance to any system component (including\napplications) conducted by a local or nonlocal entity (e.g., in- contract, warranty, in-  house,\nsoftware maintenance agreement).\n[SP 800- 88] provides guidance on media sanitization."}, "3.7.4": {"brief_description": "Check media containing diagnostic and test programs for malicious code before the media are used in organizational system s.", "detailed_description": "If, upon inspection of media containing maintenance diagnostic and test programs, organizations\ndetermine that the media contain malicious code, the incident is handled consistent with incident\nhandling policies and procedures."}, "3.7.5": {"brief_description": "Require multifactor  authentication to establish nonlocal maintenance sessions via external network connections and terminate such connections when  nonlocal maintenance is complete.", "detailed_description": "Nonlocal maintenance and diagnostic activities are those activities conducted by individuals communicatin g through an external network. The authentication techniques employed  in the\nestablishment of these nonlocal maintenance and diagnostic sessions reflect the network access\nrequirements in 3.5.3\n."}, "3.7.6": {"brief_description": "Supervise the maintenance activities of maintenance personnel without required access authorization.", "detailed_description": "This requirement applies to individuals who are performing hardware or software maintenance on\norganizational sys tems, while 3.10.1  addresses physical access for individuals whose maintenance\nduties place them within the physical protection perimeter of the systems (e.g., custodial staff,\nphysical plant maintenance personnel). Individuals not previously identified as authorized\nmainte nance personnel, such as information technology manufacturers, vendors, consultants, and\nsystems integrators, may require privileged access to organizational systems, for example, when required to conduct maintenance activities with little or no notice. Or ganizations may choose to\nissue temporary credentials to these individuals based on organizational risk assessments.\nTemporary credentials may be for one- time use or for very limited time periods."}}}, "3.8": {"title": "MEDIA  PROTECTION", "sections": {"3.8.1": {"brief_description": "Protect (i.e., physically control and securely store) system media  containing CUI, both paper and digital.", "detailed_description": "System media includes digital and non- digital media. Digit al media includes diskettes, magnetic\ntapes, external and removable hard disk drives, flash drives, compact disks, and digital video disks.\nNon -digit al media includes paper and microfilm. Protecting digital media includes limiting access\nto design specifications stored on compact disks or flash drive s in the media library to the project\nleader and any individuals on the development team. Physically controlling syst em media includes\nconducting inventories, maintaining accountability for stored media, and ensuring procedures are\nin place to allow indivi duals to check out and return media to the media library. Secure  storage\nincludes a locked drawer, desk, or cabinet, or a controlled media library.\nAccess to CUI on system media can be limited by physically controlling such media, whic h includes\nconducting  inventories, ensuring procedures are in place to allow individuals to check out and\nreturn media to the media library, and maintaining accountability for all stored media.\n[SP 800- 111] provides guidance on storage encryption technologies for end user devices."}, "3.8.2": {"brief_description": "Limit access to CUI on system media to authorized users.", "detailed_description": "Access can be limited by physically controlling system media and secure storage  areas . Physically\ncontrolling syst em media includes conducting inventories, ensuring procedures are in place to\nallow individuals to check out and return system media to the media library, and maintaining\naccountability for all stored media . Secure  storage includ es a locked drawer, desk, or cabinet, or a\ncontrolled media library."}, "3.8.3": {"brief_description": "Sanitize or destroy system media containing CUI before disposal or release for reuse.", "detailed_description": "This requirement applies to all system media, digital and non -digital, subject to disposal or reuse.\nExamples include: digital media found in workstations, network components, scanners, copiers,\nprinters, notebook computers, and mobile devices; and non- digital media such as paper and\nmicrofilm. The sanitization process removes information from the media such that the information cannot be retrieved or reconstructed. Sanitization techniques, including clearing, purging,\ncryptographic erase, and destruction, prevent the disclosure of information to unauthorized individuals when such media is released for reuse or disposal.\nOrganizations determine the appropriate sanitization methods, recognizing that destruction may\nbe necessary when other methods cannot be applied to the media requiring sanitization.\nOrganizations use discretio n on the employment of sanitization techniques and procedures for\nmedia containing information that is in the publi c domain or publicly releasable  or deemed to have\nno adverse impact on organizations or individuals if released for reuse or disposal. Sanitization of\nnon-digit al media includes destructio n, removing CUI from document s, or redacting selected\nsections or words from a document by obscuring the redacted sections or words in a manner equivalent in effectiveness to removing the words or sections from the document. NARA policy\nand guidance contro l sanitization processes  for controlled unclassified information.\n[SP 800- 88\n] provides guidance on media sanitization.\nDerived Security Requirements"}, "3.8.4": {"brief_description": "Mark media with necessary CUI markings and distribution limitations.27", "detailed_description": "The term security marking refers to the application or use of human -readable security attributes.\nSystem media includes digital and non- digital media. Marking of system media reflects applicable\nfederal laws, Executive Orders, directives, policies, and regulations.  See [NARA MARK ]."}, "3.8.5": {"brief_description": "Control  access to media containing CUI and maintain accountability for media during transp ort outside of controlled areas.", "detailed_description": "Controlled areas are areas or spaces for which organizations provide p hysical or procedural\ncontrols  to meet the requirements established for protecting systems and information. Controls\nto maintain accountability for med ia during transport include locked containers and cryptography.\nCryptographic mechanisms can provide confidentiality and integrity protections depending upon\nthe mechanisms used. Activities associated with transport include the actual transport as well as\nthose activities such as releasing media for transport and ensuring that media enters the\nappropriate transport processes. For the actual transport, authorized transport and courier\npersonnel may include individuals external to  the organization. Maintaining accountability of\nmedia during t ransport includes restricting transport activities to authorized personnel  and\ntracking and obtaining explicit records of transport activities as the media moves through the\ntransportation system to prevent and detect loss, destruction, or tampering."}, "3.8.6": {"brief_description": "Implement cryptographic mechanisms to protect the confidentiality of CUI stored on digital media during transport unless otherwise protected by alternative physical safeguards.", "detailed_description": "This requirement applies to portable storage devices (e.g., USB memory sticks, digital video disks, compact disks, external or removable har d disk drives).  See [NIST CRYPTO\n].\n[SP 800- 111] provides guidance on storage encryption technologies for end user devices."}, "3.8.7": {"brief_description": "Control the use of removable media on system components.", "detailed_description": "In contrast to requirement 3.8.1 , which restricts user access to media, this requirement restricts\nthe use of certain types of media on systems, for example, restricting or prohibiting the use of flash drives or external hard disk drives. Organizations can employ techn ical and nontechnical controls\n(e.g., policies, procedures, and rules of behavior) to control the use of system media. Organizations\nmay control the use of portable storage devices, for example, by using physical cages on\nworkstations to prohibit access to certain external ports, or disabling or r emoving the ability to\ninsert, read, or write to such devices.\nOrganizations may also limit the use of portable storage devices to only approved devices including\ndevices provided by the organization, devices provided by other approved organizations, and\ndevices that are not personally owned. Finally, organizations may control the use of portable\n27 The implementation of this requiremen t is per marking guidance in  [32 CFR 2002] and [ NARA CUI ]. Standard Form\n(SF) 902 (approximate size 2.125\u201d x 1.25\u201d) and SF 903 (approximate size 2.125\u201d x .625\u201d) can be used on media that\ncontain s CUI such as hard drives, or USB  devices . Both forms are available from https://www.gsaadvantage.gov . SF\n902: NSN 7540- 01-679- 3318. SF 903: NSN 7540- 01-679- 3319.\nstorage devices based on t he type of device, prohibiting the use of  writeable, portable devices,\nand implementing this restriction by disabling or removing the cap ability to write to such devices."}, "3.8.8": {"brief_description": "Prohibit the use of portable storage devices when such devices  have no identifiable owner.", "detailed_description": "Requiring identifiable  owners (e.g., individuals, organizations, or projects) for porta ble storage\ndevices reduces the overall risk of using such technologies by allowing organizations to assign\nresponsibility and accountability for addressing known vulnerabilities in the devices (e.g., insertion\nof malicious code)."}, "3.8.9": {"brief_description": "Protect the confidentiality of backup CUI at storage locations .", "detailed_description": "Organizations can employ cryptographic mechanisms or  alternative physical controls  to protect\nthe confidentiality of backup information at designated storage locations. Backed -up information\ncontaining CUI may include system -level information and user- level information. System -level\ninformation includes system -state information , operating system software, application software,\nand licenses. User- level information includes information other than system -level information."}}}, "3.9": {"title": "PERSONNEL  SECURITY", "sections": {"3.9.1": {"brief_description": "Screen individuals prior to authorizing access to organizational systems containing CUI.", "detailed_description": "Personnel security screening (vetting) activities involve the evaluation /assessment  of individual \u2019s\nconduct, integrity, judgment, loyalty, reliability , and stability ( i.e., the trustworthiness of the\nindividual ) prior to authorizing access to organization al systems containing CUI . The screening\nactivities reflect applicable federal laws, Executive Orders, directives, policies, regulations, an d\nspecific criteria established for the level of access required for assigned positions."}, "3.9.2": {"brief_description": "Ensure that organizational systems containing CUI are protected during and after personnel actions such as terminations and transfers.", "detailed_description": "Protecting CUI during and after personnel ac tions may include return ing system -related property\nand conducting exit interviews. System -related property includes hardware authentication tokens,\nidentification cards, system administration technica l manuals, keys, and building passes. Exit\ninterviews ensure that individuals who have been terminated understand the security constraints imposed by being former employees and that proper accountability is achieved for system -related\nproperty. Security to pics of interest at exit interviews can include reminding terminated individuals\nof nondisclosure agreements and potential limitations on future employment. Exit interviews may\nnot be possible for some terminated individuals, for example, in cases related to job abandonment,\nillnesses, and non -availability of supervisors. For termination actions, timely execution is essential\nfor individuals terminated for cause. In certain situations, organizations consider disabling the\nsystem accounts of individuals that are being terminated prior to the individuals being notified.\nThis requirement applies to reassignments or transfers of individuals when the personnel action is\npermanent or of such extended durations as to require protection. Organizations define the CUI\nprotections appropriate for the types of reassignments or tran sfers, whether permanent or\nextended. Protections that may be required for transfers or reassignments to other positions\nwithin orga nizations include returning old and issuing new keys, identification cards, and building\npasses; changing system access authorizations (i.e., privileges); closing system accounts and\nestablishing new accounts; and providing for access to official records to which individuals had\naccess at previous work locations and in previous system accounts.\nDerived Security Requirements\nNon e."}}}, "3.10": {"title": "PHYSICAL  PROTECTION", "sections": {"3.10.1": {"brief_description": "Limit physical access to organizational systems, equipment, and the respective operating environm ents to authorized individuals.", "detailed_description": "This requirement applies to employees, individuals with permanent physical access authorization\ncredentials, and visitors. Authorized individuals have credentials that  include badges, identification\ncards, and smart cards. Organizations determine the strength of auth orization credentials needed\nconsistent with applicable laws, directives, policies, regulations, standards, procedures, and\nguidelines. This requirement applies only to areas within facilities that have not been designated\nas publicly accessible.\nLimiting physical access to equipment may include placing equipment in locked rooms or other\nsecured areas and allowing access to authorized individuals only;  and placing equipment in\nlocations that can be monitored by organizational personnel. Computing devices, e xternal disk\ndrives, networking devices, monitors, printers, copiers, scanners, facsimile machines, and audio\ndevices are examples of equipment."}, "3.10.2": {"brief_description": "Protect and monitor the physical facility  and support infrastructure for  organizational systems.", "detailed_description": "Monitoring of physical access includes publicly accessible areas within organizational facilities. This\ncan be accomplished, for example, by the employment of guards; the use of sensor devi ces; or the\nuse of video surveillance equipment such as cameras. Examples of support infrastructure include\nsystem distribution, transmission, and pow er lines. Security controls  applied to the support\ninfrastructure prevent accidental damage, disruption, a nd physical tampering. Such controls  may\nalso be necessary to prevent eavesdropping or modification of unencrypted transmissions.\nPhysical access controls to support infras tructure include locked wiring closets; disconnected or\nlocked spare jacks; protecti on of cabling by conduit or cable trays; and wiretapping sensors.\nDerived Security Requirements"}, "3.10.3": {"brief_description": "Escort visitors  and monitor visitor activity .", "detailed_description": "Individuals with permanent physical access authorization credentials are not considered visitors.\nAudit logs can be used to monitor visitor activity."}, "3.10.4": {"brief_description": "Maintain audit logs  of physical access .", "detailed_description": "Organizations have flexibility in the types of audit logs employed. Audit logs can be procedural\n(e.g., a written log of individuals accessing the facility ), automated (e.g., capturing ID provided by\na PIV card), or some combination thereof. Physical access points can include facility access points, interior access points to systems or system components requiring supplemental access controls,\nor both.  System components  (e.g., workstations, notebook computers) may be in areas designated\nas publicly accessible with organizations safeguarding access to such devices.\n3.10.5\nControl and manage physical access devices.\nPhysical access devices include keys, locks, combinations, and card readers."}, "3.10.6": {"brief_description": "Enforce safeguarding measures for CUI  at alternate work sites.", "detailed_description": "Alternate work site s may include government facilities or the private residences of employees.\nOrganizations may define different security requirements for specific alternate work sites or types\nof sites depending on the work -related activities conducted at those sites.\n[SP 800- 46] and [ SP 800- 114] provide guidance on enterprise and user security when teleworking."}}}, "3.11": {"title": "RISK  ASSESSMENT", "sections": {"3.11.1": {"brief_description": "Periodically assess the risk to organizational operations (including mission, functions, image, or reputation), organizational assets, and individuals, resulting from the operation of organizational systems and the associated processing, storage, or transmissi on of CUI .", "detailed_description": "Clearly defined system boundaries are a prerequisite for effective risk assessments. Such risk\nassessments consider threats, vulnerabilities, likelihood, and impact to organizational operations,\norganizational assets, and individuals based on the operation and use of organizational systems.\nRisk assessments also consider risk from external parties (e.g., service providers, contractors\noperating systems on behalf of the organization, individuals accessing organizational systems,\noutsourcing entities). Risk assessments, either formal or informal, can be conducted at the\norganization level, the mission or business process level, or the system level, and at any phase in\nthe system development life cycle.\n[SP 800- 30] provides guidance on conducting risk assessments.\nDerived Security Requirements"}, "3.11.2": {"brief_description": "Scan for vulnerabilities in organizational system s and applications periodically and when ne w vulnerabilities affecting those system s and applications are identified.", "detailed_description": "Organizations determine the required vulnerability scanning for all system components, ensuring\nthat potential sources of vulnerabilities such as networked printers, scanners, and copiers are not\noverlooked. The vulnerabilities to be scanned are readily up dated as new vulnerabilities are\ndiscovered, announced, and scanning methods developed. This process ensures that potential\nvulnerabilities in the system are identified and addressed as quickly as possible. Vulnerability\nanalyses for custom software applic ations may require additional approaches such as static\nanalysis, dynamic analysis, binary analysis, or a hybrid of the three approaches. Organizations can\nemploy these analysis approaches in source code reviews and in a variety of tools (e.g., static\nanal ysis tools, web -based application scanners, binary analyzers) and in source code reviews.\nVulnerabilit y scanning includes : scanning for patch levels; scanning for functions, ports, protocols,\nand services that should not be accessible to users or devices; and scanning for improperly configured or incorrectly operating information flow control mechanisms.\nTo facilitate interoperability, organizations consider using products that are Security Content\nAutomated Protocol (SCAP) -validated, scanning tools that ex press vulnerabilities in the Common\nVulnerabilities and Exposures (CVE) naming convention, and that employ  the Open Vulnerability\nAssessment Language (OVAL) to determine the presence of system vulnerabilities. Sources for\nvulnerability information include the Common Weakness Enumeration (CWE) listing and the\nNational Vulnerability Database (NVD).\nSecurity assessments, such as red team exercises, provide additional sources of potential\nvulnerabilities for which to scan. Organizations also consider using scan ning tools that express\nvulnerability impact by the Common Vulnerability Scoring System (CVSS). In certain situations, the\nnature of the vulnerability scanning may be more intrusive or the system component that is the\nsubject of the scanning may contain hi ghly sensitive information. Privileged access authorization\nto selected system components facilitates thorough vulnerability scanning and protects the\nsensitive nature of such scanning.\n[SP 800- 40\n] provides guidance on vulnerability management."}, "3.11.3": {"brief_description": "Remediate vulnerabilities in accordance with risk assessmen ts.", "detailed_description": "Vulnerabilities discovered,  for example, via the scanning conducted in response to 3.11.2 , are\nremediated with consideration of the related assessment of risk. The consideration of risk influences the prioritization of remediation efforts and the level of effort to be expended in the\nremediation for specific vulnerabilities."}}}, "3.12": {"title": "SECURITY  ASSESSMENT", "sections": {"3.12.1": {"brief_description": "Periodically assess the security controls in organizational systems to determine if the controls are e ffective in their application.", "detailed_description": "Organizations assess security controls in organizational systems and the environments in which\nthose systems operate as part of the system development life cycle. Security controls are the\nsafeguards or countermeasures organizations implement to satisfy security requirements. By\nassessing the implemented security controls, organizations determine if the security safeguards or\ncountermeasures are in place and operating as intended. Security control asse ssments ensure that\ninformation security is built into organizational systems; identify weaknesses and deficiencies early in the development process; provide essential information needed to make risk -based decisions;\nand ensure compliance to vulnerability mitigation procedures. Assessments are conducted on the\nimplemented security controls as documented in system security plans.\nSecurity assessment reports document assessment results in sufficient detail as deemed necessary\nby organizations, to determine the accuracy and completeness of the reports and whether the\nsecurity controls are implemented correctly, operating as intended, and producing the desired\noutcome with respect to meeting security requirements. Security assessment results are prov ided\nto the individuals or roles appropriate for the types of assessments being conducted.\nOrganizations ensure that security assessment results are current, relevant to the determination\nof security control effectiveness, and obtained with the appropriate  level of assessor\nindependence. Organizations can choose to use other types of assessment activities such as vulnerability scanning and system monitoring to maintain the security posture of systems during\nthe system life cycle.\n[SP 800- 53] provides guidance on security and privacy controls for systems and organizations.  [\nSP\n800-53A] provides guidance on developing security assessment plans and conducting assessments ."}, "3.12.2": {"brief_description": "Develop and implement plans of action designed to correct deficiencies and reduce or eliminate vulnerabilities in orga nizational systems.", "detailed_description": "The plan of action is a key document in the information security program. Organizations develop\nplans of action that describe how any unimplemented security requirements will be met and how any planned mitigations will be implemented. Organizations can document the system security\nplan and plan of action as sep arate or combined documents and in any chosen format.\nFederal agencies may consider the submitted system security plans and plans of action as critical\ninputs to an overall risk management decision to process, store, or transmit CUI on a system hosted\nby a nonfederal organization and whether it is advisable to pursue an agreement or contract with\nthe nonfederal organization.  [NIST CUI\n] provides supplemental material for Special Publication\n800-171 including templates for plans of action."}, "3.12.3": {"brief_description": "Monitor security controls on an ongoing basis to ensure the continued effectiveness of the controls.", "detailed_description": "Continuous monitoring programs facilitate ongoing awareness of threats, vulnerabilities, and information security to support organizational risk management decisions. The terms continuous\nand ongoing imply that organizations assess and analyze security controls and information\nsecurity -related risks at a frequency sufficient to support risk -based decisions. The results of\ncontinuous monitoring programs generate appropriate risk response actions by organizations.\nProviding access to security information on a continuing basis through reports or dashboards gives\norganizational offici als the capability to make effective and timely risk management decisions.\nAutomation supports more frequent updates to hardware, software, firmware inventories, and\nother system information. Effectiveness is further enhanced when continuous monitoring outputs\nare formatted to provide information that is specific, measurable, actionable, relevant, and timely.\nMonitoring requirements, including the need for specific monitoring, may also be referenced in\nother requirements.\n[SP 800- 137\n] provides guidance on continuous monitoring."}, "3.12.4": {"brief_description": "Develop, document, and periodically update system security plans that describe system boundaries, system environments of operation , how security requirements are implemented, and the relationships with or connections to other systems .28", "detailed_description": "System security plans relate security requirements to a set of security controls. System security\nplans also describe, at a high level, how the security co ntrols meet those security requirements,\nbut do not provide detailed, technical descriptions of the design or implementation of the controls.\n28 There is no prescribed format or specified level of detail for system security pla ns. However, organizations ensure\nthat the required information in 3.12.4 is conveyed in those plans.\nSystem s ecurity plans contain sufficient information to enable a design and implementation that\nis unambiguously c ompliant with the intent of the plans and subsequent determinations of risk if\nthe plan is implemented as intended. Security plans need not be single documents; the plans can\nbe a collection of various documents including documents that already exist. Effe ctive security\nplans make extensive use of references to policies, procedures, and additional documents (e.g., design and implementation specifications) where more detailed information can be obtained. This\nreduces the documentation requirements associated  with security programs and maintains\nsecurity -related information in other established management/operational areas related to\nenterprise architecture, system development life cycle, systems engineering, and acquisition.\nFederal agencies may consider the submitted system security plans and plans of action as critical\ninputs to an overall risk management decision to process, store, or transmit CUI on a system hosted\nby a nonfederal organization and whether it is advisable to pursue an agreement or contract with\nthe nonfederal organization.\n[SP 800- 18] provides guidance on developing security plans.  [NIST CUI\n] provides supplemental\nmaterial for Special Publication 800 -171 including templates for system security plans.\nDerived Security Requirements\nNone."}}}, "3.13": {"title": "SYSTEM  AND  COMMUNICATIONS  PROTECTION", "sections": {"3.13.1": {"brief_description": "Monitor, cont rol, and protect communications (i.e., information transmitted or received by organizational systems) at the external boundaries and key internal boundaries o f organizational systems.", "detailed_description": "Communications can be monitored, controlled, and protected at boundary components and by\nrestricting or prohibit ing interfaces in organizational systems. Boundary c omponents include\ngateways, routers, firewalls, guards, network -based malicious code analysis and virtualization\nsystems, or encrypted tunnels implemented within a system security architecture (e.g., rout ers\nprotecting firewalls or application gateways residing on protected subnetworks). Restricting or prohibiting interfaces in organiza tional systems includes restricting external web communications\ntraffic to designated web servers within managed interface s and prohibiting external traffic that\nappears to be spoofing internal addresses.\nOrganizations consider the shared nature of commercial telecommunications services in the\nimplementation of security requirements associated with the use of such services. C ommercial\ntelecommunications services are commonly based on network components and consolidated management systems shared by all attached commercial customers and may also include third\nparty -provided access lines and other service elements. Such transmission services may represent\nsources of increased risk despite contract security provisions.\n[SP 800- 41] provides guidance on firewalls and firewall policy.  [SP 800- 125B\n] provides guidance on\nsecurity for virtualization technologies."}, "3.13.2": {"brief_description": "Employ architectural designs, software development techniques, and systems engineering principles that promote e ffective information security within organizational systems.", "detailed_description": "Organizations apply systems security engineering principles to new development systems or\nsystems undergoing major upgrades. For legacy systems, organizations apply systems security\nengineering principles to system upgrades and modifications to the extent feasible, given the\ncurrent state of hardware, software, and firmware components within those systems. The\napplication of systems security engineering concepts and principles helps to develop trustworthy,\nsecure, and resilient systems and system components and reduce the susceptibility of\norganizations to disruptions, hazards, and threats. Examples of these concepts and principles include developing layered protections; establishing security policies, architecture, and controls as\nthe foundation for design;  incorporating security requirements into the system development life\ncycle; delineating physical and logical security boundaries; ensuring that developers are trained on\nhow to build secure software; and performing threat modeling to identify use cases, t hreat agents,\nattack vectors and patterns, design patterns, and compensating controls needed to mitigate risk.\nOrganizations that apply security engineering concepts and principles can facilitate the\ndevelopment of trustworthy, secure systems, system compo nents, and system services; reduce\nrisk to acceptable levels; and make informed risk -management decisions.\n[SP 800- 160-1\n] provides guidance on systems security engineering.\nDerived Security Requirements"}, "3.13.3": {"brief_description": "Separate user functionality from system management functionality .", "detailed_description": "System management functionality i ncludes functions necessary to administer databases, network\ncomponents, workstations, or servers, and typically requires privileged user access. The separation\nof user functionality from system management functionality is physical or logical. Organizations\ncan implement separation of system management functionality from user functionality by using\ndifferen t computers, different central processing units, different instances of operating systems,\nor different network addresses; virtualization techniques; or combinations of these or other methods, as appropriate. This type of se paration includes web administra tive interfaces that use\nseparate authentication methods for users of any other system resources. Separation of system\nand user functionality may include isolating administrative interfaces on different domains and\nwith additional access controls.\n3.13.4\nPrevent unauthorized and unintended information transfer vi a shared system resources.\nThe control of information in shared system resources (e.g., registers, cache memory, main memory, hard disks) is also commonly referred to as object reuse and residual information\nprotection. This requirement prevents information produced by the actions of prior users or roles\n(or the actions of processes acting on behalf of prior users or roles) from being available to a ny\ncurrent users or roles (or current processes acting on behalf of current users or roles) that obtain\naccess to shared system resources after those resources have been released back to the system.\nThis requirement also applies to encrypted representation s of information. This requirement does\nnot address information remanence, which refers to residual representation of data that has been\nnominally deleted; covert channels (including storage or timing channels) where shared resources\nare manipulated to vio late information flow restrictions; or components within systems for which\nthere are only single users or roles.\n3.13.5\nImplement subnetworks for publicly accessible system components that are physically or\nlogically separated fro m internal networks.\nSubnetworks that are physically or logically separated from internal networks are referred to as demilitarized zones (DMZs). DMZs are typically implemented with boundary control devices and\ntechni ques that include routers, g ateways, firewalls, virtualization, or cloud -based technologies.\n[SP 800- 41] provides guidance on firewalls and firewall policy. [SP 800- 125B] provides guidance on\nsecurity for virtualization technologies."}, "3.13.6": {"brief_description": "Deny network communications traffic by default and allow network communications traffic by exception (i.e., deny all, permit by exception) .", "detailed_description": "This requirement applies to inbound and outbound netwo rk communications traffic at the system\nboundary and at identified points within the system. A deny -all, permit -by-exception network\ncommunications traffic policy ensures that only those connections which are essential and\napproved are allowed."}, "3.13.7": {"brief_description": "Prevent remote devices  from simultaneously establishing non-remote connections with organizational system s and communicating via some other connection to resources in external networks  (i.e., split tunneling) .", "detailed_description": "Split tunneling might be desirable by remote users to communicate with local system resources\nsuch as printers or file servers.  However, split tunneling allows  unauthorized external connections,\nmaking the system more vulnerable to attack and to exfiltration of organizational information. This\nrequirement is implemented in remote devices (e.g., notebook computers, smart phones, and\ntablets) through configuration  settings to disable split tunneling in those devices, and by\npreventing configuration settings from being readily configurable by users. This requirement is implemented in the system by the detection of split tunneling (or of configuration settings that\nallow split tunneling) in the remote device, and by prohibiting the connection if the remote device\nis using split tunneling.\n3.13.8\nImplement cryptographic mechanisms to prevent unauthorized disclosure of CUI  during\ntransmission unless otherwise protected by alternative  physica l safeguards .\nThis requirement applies to internal and external networks and any system components that can\ntransmit information including  servers, notebook computers, desktop  computers, mobile devices,\nprinters, copiers, scanners, and facsimile machines. Communication paths outsi de the physical\nprotection of controlled boundaries  are susceptible to both interception and modification.\nOrganizations relying on commercial provide rs offering transmission services as commodity\nservices rather than as fully dedicated services (i.e., services which can be highly specialized to\nindividual customer needs), may find it difficult to obtain the necessary assurances regarding the\nimplementa tion of the controls  for trans mission confidentiality. In such  situations, organizations\ndetermine what types of confidentiality serv ices are available in commercial telecommunication\nservice packages. If it is infeasible or impractical to obtain the neces sary safeguards and assurances\nof the effectiveness of the safeguards through appropriate contracting vehicles, organizations implement compensating safeguards or explicitly accept the additional risk. An example of an\nalternative physical safeguard is a p rotected distribution system (PDS) where the distribution\nmedium is protected against electronic or physical intercept, thereby ensuring the confidentiality\nof the  information being transmitted. See [NIST CRYPTO\n]."}, "3.13.9": {"brief_description": "Terminate network connections associated with communications sessions at the end of the sessions or after a defined period of inactivity .", "detailed_description": "This requirement applies to internal and external networks. Terminating ne twork connections\nassociated with communications  sessions include de -allocating associated TCP/IP address or port\npairs at the operating system level, or de -allocating networking assignments at the application\nlevel if multiple application sessions are using a single, operating system -level network connection.\nTime periods of user inactivity may be established by organiza tions and include time periods by\ntype of network access or for specific network accesses."}, "3.13.10": {"brief_description": "Establish  and manage  cryptographic keys for cryptography employ ed in organizational system s.", "detailed_description": "Cryptographic key management and establishment can be performed using manual procedures\nor mechanisms supported by manual procedures. Organizations define key management\nrequirements in accordance with applicable federal laws, Executive Orders, policies, directives,\nregulations, and standards  specifying appropriate options, levels, and parameters.\n[SP 800- 56A] and [ SP 800- 57-1] provide guidance on cryptographic key management and key\nestablishment ."}, "3.13.11": {"brief_description": "Employ  FIPS -validated cryptography when used to protec t the confidentiality of CUI .", "detailed_description": "Cryptography can be employed to support many security so lutions including the protection of\ncontrolled unclassified information, the provision of digital signatures, and the enforcement of\ninformation separation when authorized individuals have the necessary clearances for such\ninformation but lack the necessary formal access ap provals. Cryptography can also be used to\nsupport random number generation and hash generation. Cryptographic standards include FIPS-\nvalidated cryptography and /or NSA-approved cryptography.  See [NIST CRYPTO ]; [NIST CAVP ];\nand [NIST CMVP ]."}, "3.13.12": {"brief_description": "Prohibit  remote activation  of collaborativ e computing devices and provide  indication of devices in use to users present at the  device.29", "detailed_description": "Collaborative computin g devices include networked white boards, cameras, and microphones.\nIndicati on of use includes signals to users when collaborative computing devices are activa ted.\nDedicated video conferencing systems, which rely on one of the participants calling or connecting\nto the other party to activate the video conference, are excluded."}, "3.13.13": {"brief_description": "Control and monitor the use of mobile code .", "detailed_description": "Mobile code technologies include Java, JavaScript, ActiveX, Postscript, PDF, Flash animations,\nand VBScript. Decisions regarding the use of mobile code in organizational systems are based on\nthe potential for the code to cause damage to the systems if used maliciously. Usage restrictions\nand implementation guidance apply to the selection and use of mobile code installed on servers\nand mobile code downloaded and executed on individual workstations, notebook computers,\nand devices (e.g., smart phones). Mobile code policy and procedures address controlling or\npreventing the development, acquisition, or introduction of unacceptable mobile code in systems, including requiring mobile code to be digitally signed by a trusted source.\n29 Dedicated video conferencing systems, which rely on one of the participants calling or connecting to the other\nparty to activate the video conference, are excluded.\n[SP 800- 28] provides guidance on mobile code."}, "3.13.14": {"brief_description": "Control and monitor the use of Voice over Internet Protocol  (VoIP) technologies .", "detailed_description": "VoIP has different requirements, features, functionality, availability, and service limitations when\ncompared with the Plain Old Telephone Service (POTS) (i.e., the standard te lephone service ). In\ncontrast, other telephone services are based on high- speed,  digital communications lines, such\nas Integrated Services Digital Network (ISDN) and Fiber Distributed Data Interface (FDDI). The\nmain distinctions between POTS and non- POTS services are speed and bandwidth. To address\nthe threats associated with VoIP, us age restrictions and implementation guidelines are based on\nthe potential for the VoIP technology to cause damage to the system if it is used maliciously.\nThreats to VoIP are similar to those inherent with any Internet- based application.\n[SP 800- 58] provides guidance on Voice Over IP Systems."}, "3.13.15": {"brief_description": "Protect the authenticity  of communications sessions.", "detailed_description": "Authenticity pr otection includes protecting against man -in-the-middle attacks, session hijacking,\nand the insertion of false information into communications sessions. This requirement addresses\ncommunications protection at the session versus packet level (e.g., sessions in service -oriented\narchitectures pro viding web -based services) and establishes grounds for confidence at both ends\nof communications sessions in ongoing identities of other parties and in the validity of\ninformation transmitted.\n[SP 800- 77], [ SP 800 -95], and [ SP 800- 113] provide guidance on secure communications sessions."}, "3.13.16": {"brief_description": "Protect the confidentiality of CUI at rest.", "detailed_description": "Information at rest refers to the state of information when it is not in process or in transit and is\nlocated on storage devices as specific components of systems. The focus of protection at rest is\nnot on the type of storage device or the frequency of access but rather the state of the\ninformation. Organizations can use different mechanisms to achieve confidentiality protections,\nincluding the use of cryptographic mechanisms and file share scanning. Organizations may also\nuse other controls including secure off -line storage in lieu of online storage when adequate\nprotection of information at rest cannot otherwise be achieved or continuous monitoring to\nidentify malicious code at rest.  See [NIST CRYPTO ]."}}}, "3.14": {"title": "SYSTEM  AND  INFORMATION  INTEGRITY", "sections": {"3.14.1": {"brief_description": "Identify, repo rt, and correct system flaws in a time ly manner.", "detailed_description": "Organizations identify systems that are affected by announced software and firmware flaws\nincluding potential vulnerabilit ies resulting from those flaws and report this information to\ndesignated personnel with information security responsibilities. Security -relevan t updates include\npatches, service packs, hot fixes, and anti -virus signatures. O rgani zations address flaws discovered\nduring security assessments, continuous monitoring, incident response activities, and system error\nhandling. Organizations can take advantage of available resources such as the Common Weakness\nEnumeration (CWE) database or Common Vulnerabiliti es and Exposures (CVE) database  in\nremediating flaws discovered in organizational systems.\nOrganization -defined time periods for updating security -relevant software and firmware may vary\nbased on a variety of factors i ncluding the criticality of the update (i.e., severity of the vulnerability\nrelated to the discovered flaw). Some types of flaw remediation may require more testing t han\nother types of remediation.\n[SP 800-40] provides guidance on patch management technologies."}, "3.14.2": {"brief_description": "Provide protection from malicious code at designated locations within organizational systems.", "detailed_description": "Designated locations include system entry and exit points which may include firewalls, remote -\naccess servers, workstations, electronic mail servers, web servers, proxy servers, notebook\ncomputers, and mobile devices. Malicious code includes viruses, worms,  Trojan horses, and\nspyware. Malicious code can be encoded in various formats (e.g., UUENCODE, Unicode), contained\nwithin compressed or hidden files, or hidden in files using techniques such as steganography.\nMalicious code can be inserted into systems in a variety of ways including web accesses, electronic\nmail, electronic mail attachments, and portable storage devices. Malicious code insertions occur\nthrough the exploitation of system vulnerabilities.\nMalicious code protection m echanisms include anti -virus signature definitions and reputation -\nbased technologies. A variety of technologies and methods exist to limit or eliminate the effects of malicious code. Pervasive configuration management and comprehensive software integrity\ncontrols may be effective in  preventing execution of unauthorized code. In addition to commercial\noff-the-shelf software, malicious code may also be present in custom -built software. This could\ninclude  logic bombs, back doors, and other types of cyber -attacks that could affect organi zational\nmissions/business functions. Traditional malicious code protection mechanisms cannot always\ndetect such code. In these situations, organizations rely instead on other safeguards including\nsecure coding practices, configuration management and contr ol, trusted procurement processes,\nand monitoring practices to help ensure that software does not perform functions other than the\nfunctions intended.\n[SP 800- 83\n] provides guidance on malware incident prevention."}, "3.14.3": {"brief_description": "Monitor system security alerts and advisories and take action  in response.", "detailed_description": "There are many publicly available sources of system security alerts and advisories. For example,\nthe Department of Homeland Security\u2019s Cybersecurity and Infrastructure Security Agency (CISA)\ngenerates security alerts and advisories to maintain situational awareness across the federal\ngovernment and in nonfederal organizations. Software vendors, subscription services, and\nindustry information sharing and analysis centers (ISACs) may also provide security alerts and\nadvisories. Examples of response actions in clude notifying relevant external organizations, for\nexample, external mission/business partners, supply chain partners, external service providers,\nand peer or supporting organizations\n[SP 800- 161] provides guidance on supply chain risk management.\nDerived Security Requirements"}, "3.14.4": {"brief_description": "Update malicious code protection mechanisms when new releases are available.", "detailed_description": "Malicious code protection m echanisms include anti -virus signature definitions and reputation -\nbased technologies. A variety of technologies and methods exist to limit or eliminate the effects of\nmalicious code. Pervasive configuration management and comprehensive software integrity\ncontrols may be effective in preventing execution of unauthorized code. In addition to commercial\noff-the-shelf software, malicious code may also be present in custom -built software. T his could\ninclude logic bombs, back doors, and other types of cyber -attac ks that could affect organizational\nmissions/business functions. Traditional malicious code protection mechanisms cannot always detect such code. In these situations, organizations rely instead on other safeguards including\nsecure coding practices, configuration management and control, trusted procurement processes,\nand monitoring practices to help ensure that software does not perform functions other than the\nfunctions intended.\n3.14.5\nPerform periodic scans of organizational systems and real -time scans of files from external\nsources as files are  downloaded, opened,  or executed.\nPeriodic scans of organizational systems and real -time scans of files from external sources can\ndetect malicious code.  Malicious code can be encoded in various formats (e.g., UUENCODE,\nUnicode), contained within compressed or hidden files, or hidden in files using techniques such as\nsteganography. Malicious code can be inserted into systems in a variety of ways including w eb\naccesses, electronic mail, electronic mail attachments, and portable storage devices. Malicious\ncode insertions occur through the exploitation of system vulnerabilities."}, "3.14.6": {"brief_description": "Monitor organizational system s, including inbound and outbound communications traffic, to detect attacks and indi cators of potential attacks.", "detailed_description": "System monitoring includes external and internal monitoring.  External monitoring includes the\nobservation of events occurring at the sy stem boundary (i.e.,  part of perimeter defense and\nboundary protection). Internal monitoring includes the observation of events occurring within the\nsystem. Organizations can monitor systems, for example, by observing audit record activities in\nreal time o r by observing other system aspects such as access patterns, characteristics of access,\nand other actions. The monitoring objectives may guide determination of the events.  System\nmonitoring capability is achieved through a variety of tools and techniques ( e.g., intrusion\ndetection systems, intrusion prevention systems, malicious code protection software, scanning\ntools, audit record monitoring software, network monitoring software). Strategic locations for\nmonitoring devices  include selected perimeter locat ions and near server farms supporting critical\napplications, with such devices being employed at managed system interfaces. The granularity of\nmonitoring information collected is based on organizational monitoring objectives and the\ncapability of systems t o support such objectives.\nSystem monitoring is an integral part of continuous monitoring and incident response programs.\nOutput from system monitoring serves as input to continuous monitoring and incident response\nprograms. A network connection is any con nection with a device that communicates through a\nnetwork (e.g., local area network, Internet). A remote connection is any connection with a device\ncommunicating through an external network (e.g., the Internet). Local, network, and remote\nconnections can be either wired or wireless.\nUnusual or unauthorized activities or conditions related to inbound /outbound communications\ntraffic include internal traffic that indicates the presence of malicious code in systems or\npropagating among system components, the unauthorized exporting of information, or signaling\nto external systems. Evidence of malicious code is used to identify potentially compro mised\nsystems or system components. System monitoring requirements, including the need for specific\ntypes of system monitoring, may be referenced in other requirements.\n[SP 800- 94] provides guidance on intrusion detection and prevention systems."}, "3.14.7": {"brief_description": "Identify unauthorized use of organizational system s.", "detailed_description": "System monitoring includes external and internal monitoring. System monitoring can detect unauthorized use of organizational systems.  System monitoring is an integral part of continuous\nmonitoring and incident response programs. Monitoring is achieved through a variety of tools and\ntechniques (e.g., intrusion detection systems, intrusion prevention systems, malicious code\nprotection software, scanning tools, audit record monitoring software, network monitoring\nsoftware). Output from system monitoring serve s as input to continuous monitoring  and incident\nresponse programs.\nUnusual/ unauthorized activities or conditions related to inbound and outbound communications\ntraffic include internal traffic that indicates the presence of malicious code in systems or\npropagating among system components, the unauthorized exporting of information, or signaling\nto external systems. Evidence of malicious code is used to identify potentially compromised\nsystems or system components. System monitoring requirements, including t he need for specific\ntypes of system monitoring, may be referenced in other requirements.\n[SP 800- 94\n] provides guidance on intrusion detection and prevention systems.SP 800- 171, REVISION 2                                                                                      PROTECTING CONTROLLED UNCLASSIFIED INFORMATION"}}}}